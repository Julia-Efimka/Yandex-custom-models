{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6cZv8CtZfZW7B6HtJmeVx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Julia-Efimka/Yandex-custom-models/blob/main/Sentiment_analysis_version_December_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Устанавливаем необходимые библиотеки**"
      ],
      "metadata": {
        "id": "9WCjW1j_bps9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai\n",
        "!pip install nltk\n",
        "!pip install -U spacy --no-cache-dir\n",
        "!python -m spacy download ru_core_news_lg\n",
        "!pip install tenacity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN4seAGO75pO",
        "outputId": "95cc2ff0-a018-4d4d-ddda-47f3bc9f4c07"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.3.6-py3-none-any.whl (220 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/220.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/220.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.9/220.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.6\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Collecting weasel<0.4.0,>=0.1.0 (from spacy)\n",
            "  Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m192.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy)\n",
            "  Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m188.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "Installing collected packages: cloudpathlib, weasel, spacy\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.6.1\n",
            "    Uninstalling spacy-3.6.1:\n",
            "      Successfully uninstalled spacy-3.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.6.0 requires spacy<3.7.0,>=3.6.0, but you have spacy 3.7.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cloudpathlib-0.16.0 spacy-3.7.2 weasel-0.3.4\n",
            "2023-12-01 08:32:05.967834: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-01 08:32:05.967905: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-01 08:32:05.967945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-01 08:32:05.977478: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-01 08:32:07.321359: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting ru-core-news-lg==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_lg-3.7.0/ru_core_news_lg-3.7.0-py3-none-any.whl (513.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m513.4/513.4 MB\u001b[0m \u001b[31m972.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from ru-core-news-lg==3.7.0) (3.7.2)\n",
            "Collecting pymorphy3>=1.0.0 (from ru-core-news-lg==3.7.0)\n",
            "  Downloading pymorphy3-1.2.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m967.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dawg-python>=0.7.1 (from pymorphy3>=1.0.0->ru-core-news-lg==3.7.0)\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting docopt-ng>=0.6 (from pymorphy3>=1.0.0->ru-core-news-lg==3.7.0)\n",
            "  Downloading docopt_ng-0.9.0-py3-none-any.whl (16 kB)\n",
            "Collecting pymorphy3-dicts-ru (from pymorphy3>=1.0.0->ru-core-news-lg==3.7.0)\n",
            "  Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.23.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.1.3)\n",
            "Installing collected packages: pymorphy3-dicts-ru, dawg-python, docopt-ng, pymorphy3, ru-core-news-lg\n",
            "Successfully installed dawg-python-0.7.2 docopt-ng-0.9.0 pymorphy3-1.2.1 pymorphy3-dicts-ru-2.4.417150.4580142 ru-core-news-lg-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ru_core_news_lg')\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (8.2.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Импортируем openai и прописываем ключ**\n",
        "\n"
      ],
      "metadata": {
        "id": "W48TdOKucRVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Установка ключа API\n",
        "api_key = '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'\n",
        "openai.api_key = api_key"
      ],
      "metadata": {
        "id": "SHP5rEBGEpnn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Устанавливаем прочие библиотеки**"
      ],
      "metadata": {
        "id": "nLbVkY-Jc25d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime as dt\n",
        "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk import sent_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import spacy\n",
        "nlp = spacy.load(\"ru_core_news_lg\", disable=['textcat'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vX2aBSNpMwFu",
        "outputId": "c3d8ab42-e8df-48c5-c336-3053274d5bba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Если файл 1 - запускается этот код.\n",
        "Прописываем названия колонок, функцию предобработки, промпт к gpt и собственно запускаем sentiment analysis**"
      ],
      "metadata": {
        "id": "QTscKtYJdQL8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSF1Isx874Xs",
        "outputId": "f1ab8194-a62d-4460-f7de-186a065139ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "message:  юлия , добрый день ! проект 3327 требует корректировок , готов 3 октября 14 - 15 часов . приношу извинения задержку . [ cid:585b5116-f4b2 - 4b65-abb6 - 8714b545e56d ] \n",
            "\n",
            "\n",
            " anna kabargina \n",
            "\n",
            "\n",
            " senior manager of corporate accounts management team \n",
            "\n",
            " tel . :     +74952120989 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            " г. москва ,   бц \" золото \" ,  \n",
            " ул. золотая , 11  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            " awatera.com [ http://awatera.com/ ] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " --------------------------------------------------------------------------------\n",
            "GPT response:  \"негатив\", \"перенос или срыв сроков\"\n",
            "message:  internal \n",
            "\n",
            "\n",
            "\n",
            " добрый день ! пришлите , пожалуйста , перевод заказу s_stada-2439 . могу скачать \n",
            " личного кабинета , письма , пишет , файл найден . уважением , \n",
            "\n",
            " jsc nizhpharm [ cid : image001.png@01d9f5ee.55d738d0 ] \n",
            " [ https://www.stada.ru/?utm_source=sign&utm_content=logo ] \n",
            "\n",
            " татьяна терехова \n",
            " специалист \n",
            " отдел стандартизации химико- \n",
            "\n",
            " технологической документации \n",
            " департамент медицинской поддержки \n",
            "\n",
            " развития портфеля препаратов \n",
            "\n",
            " моб : +7 ( 915 ) 3764621 \n",
            " tatiana.terekhova@stada.ru \n",
            " https://www.stada.ru [ https://www.stada.ru/?utm_source=sign&utm_content=link ] \n",
            "\n",
            " -------------------------------------------------------------------------------- \n",
            "\n",
            " ао « нижфарм » | 101000 , россия , москва , ул. пресненская набережная , д. 6 , стр. 2 , \n",
            " 7-й эт . --------------------------------------------------------------------------------\n",
            "GPT response:  \"негатив\", \"системные/технические сбои\"\n",
            "message:  анна , добрый день ! подскажите , возможность получить качественные сканы ? сгибах места , часть текста видна . спасибо ! mariya plekhanova  \n",
            " senior manager of corporate accounts management team \n",
            "\n",
            "\n",
            "\n",
            "\n",
            " tel . :    + 7 ( 495 ) 374 56 18 \n",
            "\n",
            " mob . : + 7 968 562 84 83 \n",
            "\n",
            " г. москва , \n",
            " бц « золото » , ул. золотая , д.11 . awatera.com [ http://awatera.com/ ] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " [ https://img-fotki.yandex.ru/get/6844/65387414.7c0/0_125fa2_7dacd245_xl.gif ] \n",
            " [ https://www.liveinternet.ru/journal_proc.php?action=redirect&url=https://fotki.yandex.ru/users/shadrinagalin/view/1204130/ ] \n",
            " _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            " наша компания рада оказать дополнительные услуги : \n",
            "\n",
            "\n",
            "\n",
            "  * закупка доставка товаров - рубежа ;  \n",
            "  * получение справки мвд ( справка отсутствии судимости ) ;  \n",
            "  * помощь релокации бизнеса : https://relocation.awatera.com/  \n",
            "  * окажем услуги нотариального заверения , апостилирования легализации \n",
            "    документов ( т . ч . консульской ) ;  \n",
            "  * speakus - облачная платформа удаленного синхронного перевода ;  \n",
            "  * локализацию слоганов , брошюр , описание продукта , пользовательский \n",
            "    инструкций ;  \n",
            "  * локализация мультимедийных материалов ;  \n",
            "  * копирайтинг рерайтинг маркетинговых материалов ;  \n",
            "  * транскрипция лингвистическая экспертиза названий ;  \n",
            "  * дизайн многоязычная верстка ;  \n",
            "  * сайты ключ ; идеи реализации ( своя студия веб дизайна ) ;  \n",
            "  * видеопродакшн ( создание роликов нуля , подключение любом этапе ) .\n",
            "GPT response:  \"негатив\", \"плохое качество перевода или вёрстки\"\n",
            "Обработан файл /content/тест негатива.xlsx\n"
          ]
        }
      ],
      "source": [
        "# Настройки\n",
        "message_col_name = 'Message'\n",
        "preproc_col_name = 'Preprocessed message'\n",
        "column_name_date = 'ReceivedTime'\n",
        "neg_col_name = 'Is negative?'\n",
        "type_neg_col_name = 'Type of negative'\n",
        "start_date = dt.datetime.strptime('2023-10-01', '%Y-%m-%d').date()\n",
        "\n",
        "# Указываем имя файла, который уже загружен в Colab\n",
        "file_name = '/content/тест негатива.xlsx'  # Замените на имя вашего файла\n",
        "\n",
        "# Функция предобработки\n",
        "def preprocess_text(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    docs = nlp.pipe(sentences)\n",
        "    stopwords = nltk.corpus.stopwords.words('russian')\n",
        "    lemmatized_text = [tok.text for doc in docs for tok in doc if tok.lemma_ not in stopwords\n",
        "                                and tok.ent_type_ not in ('DATE', 'GPE', 'PERSON', 'MONEY')]\n",
        "    if len(lemmatized_text) > 1250:\n",
        "        lemmatized_text = lemmatized_text[:1250]\n",
        "    text = ' '.join(lemmatized_text)  # Сохраняем пунктуацию\n",
        "    return text.lower()\n",
        "\n",
        "system = \"\"\"\n",
        "You are a sales manager in a linguistic company. Your job is to analyze communication with clients in the Russian and English languages.\n",
        "If the message is negative, respond with the word \"негатив\" and identify also the type of the claim. Respond with one of the following:\n",
        "[\"плохое качество перевода или вёрстки\", \"перенос или срыв сроков\", \"проблемы с оплатой\", \"системные/технические сбои\", \"нехватка ресурсов\", \"проблемы с нотаризацией\", \"проблемы с доставкой\", \"плохой сервис\"].\n",
        "The output for negative messages should be as follows:\n",
        "\"негатив\", \"плохое качество перевода или вёрстки\"\n",
        "If the message is not negative, respond with \"ok\".\n",
        "\"\"\"\n",
        "\n",
        "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
        "\n",
        "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
        "def completion_with_backoff(**kwargs):\n",
        "    resp = openai.chat.completions.create(**kwargs).choices[0].message.content\n",
        "    return resp\n",
        "\n",
        "def apply_gpt(message, prompt=system, model='gpt-4-0613'):\n",
        "    resp = completion_with_backoff(\n",
        "                model=model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": prompt},\n",
        "                    {\"role\": \"user\", \"content\": message},\n",
        "                ],\n",
        "                temperature=0,\n",
        "                max_tokens=30\n",
        "                )\n",
        "    if resp not in ('ok', '\"ok\"'):\n",
        "        print('message: ', message)\n",
        "        print('GPT response: ', resp)\n",
        "    return resp\n",
        "\n",
        "# Обработка файла\n",
        "df = pd.read_excel(file_name, parse_dates=[column_name_date])\n",
        "df[column_name_date] = df[column_name_date].dt.date\n",
        "df = df[df[column_name_date] >= start_date]\n",
        "\n",
        "# Обработка данных\n",
        "df[preproc_col_name] = df[message_col_name].astype('str').apply(preprocess_text)\n",
        "df[neg_col_name] = df[preproc_col_name].apply(apply_gpt)\n",
        "\n",
        "# Сохранение результата\n",
        "output_filename = 'processed_file.xlsx'\n",
        "df.to_excel(output_filename, index=False)\n",
        "\n",
        "print(f'Обработан файл {file_name}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Если файлов несколько - запускается этот код. Файлы предварительно должны быть сложены на GoogleDrive в папку**"
      ],
      "metadata": {
        "id": "WEk8-Rg9jN7T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Подготовительным этапом премонтируем GoogleDrive**"
      ],
      "metadata": {
        "id": "Zhshnv4PjhlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL9e6OgZiz7k",
        "outputId": "1fbb1a23-66b8-426e-ab8e-285cd06fafe6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Далее запускаем собственно код для анализа нескольких файлов**"
      ],
      "metadata": {
        "id": "3wmxjfS0eyuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Настройки\n",
        "from google.colab import drive\n",
        "\n",
        "message_col_name = 'Message'\n",
        "preproc_col_name = 'Preprocessed message'\n",
        "column_name_date = 'ReceivedTime'\n",
        "neg_col_name = 'Is negative?'\n",
        "type_neg_col_name = 'Type of negative'\n",
        "start_date = dt.datetime.strptime('2023-10-01', '%Y-%m-%d').date()\n",
        "\n",
        "# Список имен файлов на Google Drive\n",
        "file_names = [\n",
        "    '/content/drive/MyDrive/emails for sentiment/тест негатива - 2.xlsx',\n",
        "    '/content/drive/MyDrive/emails for sentiment/тест негатива.xlsx',\n",
        "    # и так далее до VIP_correspondence16.xlsx\n",
        "]\n",
        "\n",
        "# Функция предобработки\n",
        "def preprocess_text(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    docs = nlp.pipe(sentences)\n",
        "    stopwords = nltk.corpus.stopwords.words('russian')\n",
        "    lemmatized_text = [tok.text for doc in docs for tok in doc if tok.lemma_ not in stopwords\n",
        "                                and tok.ent_type_ not in ('DATE', 'GPE', 'PERSON', 'MONEY')]\n",
        "    if len(lemmatized_text) > 1250:\n",
        "        lemmatized_text = lemmatized_text[:1250]\n",
        "    text = ' '.join(lemmatized_text)  # Сохраняем пунктуацию\n",
        "    return text.lower()\n",
        "\n",
        "system = \"\"\"\n",
        "You are a sales manager in a linguistic company. Your job is to analyze communication with clients in the Russian and English languages.\n",
        "If the message is negative, respond with the word \"негатив\" and identify also the type of the claim. Respond with one of the following:\n",
        "[\"плохое качество перевода или вёрстки\", \"перенос или срыв сроков\", \"проблемы с оплатой\", \"системные/технические сбои\", \"нехватка ресурсов\", \"проблемы с нотаризацией\", \"проблемы с доставкой\", \"плохой сервис\"].\n",
        "The output for negative messages should be as follows:\n",
        "\"негатив\", \"плохое качество перевода или вёрстки\"\n",
        "If the message is not negative, respond with \"ok\".\n",
        "\"\"\"\n",
        "\n",
        "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
        "\n",
        "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
        "def completion_with_backoff(**kwargs):\n",
        "    resp = openai.chat.completions.create(**kwargs).choices[0].message.content\n",
        "    return resp\n",
        "\n",
        "def apply_gpt(message, prompt=system, model='gpt-4-0613'):\n",
        "    resp = completion_with_backoff(\n",
        "                model=model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": prompt},\n",
        "                    {\"role\": \"user\", \"content\": message},\n",
        "                ],\n",
        "                temperature=0,\n",
        "                max_tokens=30\n",
        "                )\n",
        "    if resp not in ('ok', '\"ok\"'):\n",
        "        print('message: ', message)\n",
        "        print('GPT response: ', resp)\n",
        "    return resp\n",
        "\n",
        "dataframes = []\n",
        "for file_name in file_names:\n",
        "    # Чтение файла\n",
        "    df = pd.read_excel(file_name, parse_dates=[column_name_date])\n",
        "    df[column_name_date] = df[column_name_date].dt.date\n",
        "    df = df[df[column_name_date] >= start_date]\n",
        "\n",
        "    # Обработка данных\n",
        "    df[preproc_col_name] = df[message_col_name].astype('str').apply(preprocess_text)\n",
        "    df[neg_col_name] = df[preproc_col_name].apply(apply_gpt)\n",
        "\n",
        "    # Добавление обработанного датафрейма в список\n",
        "    dataframes.append(df)\n",
        "\n",
        "# Объединение всех датафреймов\n",
        "combined_df = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# Сохранение объединенного файла\n",
        "output_filename = '/content/drive/My Drive/emails for sentiment/combined_file.xlsx'\n",
        "combined_df.to_excel(output_filename, index=False)\n",
        "\n",
        "print(f'Обработаны файлы и сохранен объединенный файл {output_filename}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3J_XEQEeqJw",
        "outputId": "d658859b-994d-49e2-bef6-48b6ad2caeb7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "message:  юлия , добрый день ! проект 3327 требует корректировок , готов 3 октября 14 - 15 часов . приношу извинения задержку . [ cid:585b5116-f4b2 - 4b65-abb6 - 8714b545e56d ] \n",
            "\n",
            "\n",
            " anna kabargina \n",
            "\n",
            "\n",
            " senior manager of corporate accounts management team \n",
            "\n",
            " tel . :     +74952120989 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            " г. москва ,   бц \" золото \" ,  \n",
            " ул. золотая , 11  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            " awatera.com [ http://awatera.com/ ] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " --------------------------------------------------------------------------------\n",
            "GPT response:  \"негатив\", \"перенос или срыв сроков\"\n",
            "message:  internal \n",
            "\n",
            "\n",
            "\n",
            " добрый день ! пришлите , пожалуйста , перевод заказу s_stada-2439 . могу скачать \n",
            " личного кабинета , письма , пишет , файл найден . уважением , \n",
            "\n",
            " jsc nizhpharm [ cid : image001.png@01d9f5ee.55d738d0 ] \n",
            " [ https://www.stada.ru/?utm_source=sign&utm_content=logo ] \n",
            "\n",
            " татьяна терехова \n",
            " специалист \n",
            " отдел стандартизации химико- \n",
            "\n",
            " технологической документации \n",
            " департамент медицинской поддержки \n",
            "\n",
            " развития портфеля препаратов \n",
            "\n",
            " моб : +7 ( 915 ) 3764621 \n",
            " tatiana.terekhova@stada.ru \n",
            " https://www.stada.ru [ https://www.stada.ru/?utm_source=sign&utm_content=link ] \n",
            "\n",
            " -------------------------------------------------------------------------------- \n",
            "\n",
            " ао « нижфарм » | 101000 , россия , москва , ул. пресненская набережная , д. 6 , стр. 2 , \n",
            " 7-й эт . --------------------------------------------------------------------------------\n",
            "GPT response:  \"негатив\", \"системные/технические сбои\"\n",
            "message:  анна , добрый день ! подскажите , возможность получить качественные сканы ? сгибах места , часть текста видна . спасибо ! mariya plekhanova  \n",
            " senior manager of corporate accounts management team \n",
            "\n",
            "\n",
            "\n",
            "\n",
            " tel . :    + 7 ( 495 ) 374 56 18 \n",
            "\n",
            " mob . : + 7 968 562 84 83 \n",
            "\n",
            " г. москва , \n",
            " бц « золото » , ул. золотая , д.11 . awatera.com [ http://awatera.com/ ] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " [ https://img-fotki.yandex.ru/get/6844/65387414.7c0/0_125fa2_7dacd245_xl.gif ] \n",
            " [ https://www.liveinternet.ru/journal_proc.php?action=redirect&url=https://fotki.yandex.ru/users/shadrinagalin/view/1204130/ ] \n",
            " _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            " наша компания рада оказать дополнительные услуги : \n",
            "\n",
            "\n",
            "\n",
            "  * закупка доставка товаров - рубежа ;  \n",
            "  * получение справки мвд ( справка отсутствии судимости ) ;  \n",
            "  * помощь релокации бизнеса : https://relocation.awatera.com/  \n",
            "  * окажем услуги нотариального заверения , апостилирования легализации \n",
            "    документов ( т . ч . консульской ) ;  \n",
            "  * speakus - облачная платформа удаленного синхронного перевода ;  \n",
            "  * локализацию слоганов , брошюр , описание продукта , пользовательский \n",
            "    инструкций ;  \n",
            "  * локализация мультимедийных материалов ;  \n",
            "  * копирайтинг рерайтинг маркетинговых материалов ;  \n",
            "  * транскрипция лингвистическая экспертиза названий ;  \n",
            "  * дизайн многоязычная верстка ;  \n",
            "  * сайты ключ ; идеи реализации ( своя студия веб дизайна ) ;  \n",
            "  * видеопродакшн ( создание роликов нуля , подключение любом этапе ) .\n",
            "GPT response:  \"негатив\", \"плохое качество перевода или вёрстки\"\n",
            "message:  юлия , добрый день ! проект 3327 требует корректировок , готов 3 октября 14 - 15 часов . приношу извинения задержку . [ cid:585b5116-f4b2 - 4b65-abb6 - 8714b545e56d ] \n",
            "\n",
            "\n",
            " anna kabargina \n",
            "\n",
            "\n",
            " senior manager of corporate accounts management team \n",
            "\n",
            " tel . :     +74952120989 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            " г. москва ,   бц \" золото \" ,  \n",
            " ул. золотая , 11  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            " awatera.com [ http://awatera.com/ ] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " --------------------------------------------------------------------------------\n",
            "GPT response:  \"негатив\", \"перенос или срыв сроков\"\n",
            "message:  internal \n",
            "\n",
            "\n",
            "\n",
            " добрый день ! пришлите , пожалуйста , перевод заказу s_stada-2439 . могу скачать \n",
            " личного кабинета , письма , пишет , файл найден . уважением , \n",
            "\n",
            " jsc nizhpharm [ cid : image001.png@01d9f5ee.55d738d0 ] \n",
            " [ https://www.stada.ru/?utm_source=sign&utm_content=logo ] \n",
            "\n",
            " татьяна терехова \n",
            " специалист \n",
            " отдел стандартизации химико- \n",
            "\n",
            " технологической документации \n",
            " департамент медицинской поддержки \n",
            "\n",
            " развития портфеля препаратов \n",
            "\n",
            " моб : +7 ( 915 ) 3764621 \n",
            " tatiana.terekhova@stada.ru \n",
            " https://www.stada.ru [ https://www.stada.ru/?utm_source=sign&utm_content=link ] \n",
            "\n",
            " -------------------------------------------------------------------------------- \n",
            "\n",
            " ао « нижфарм » | 101000 , россия , москва , ул. пресненская набережная , д. 6 , стр. 2 , \n",
            " 7-й эт . --------------------------------------------------------------------------------\n",
            "GPT response:  \"негатив\", \"системные/технические сбои\"\n",
            "message:  анна , добрый день ! подскажите , возможность получить качественные сканы ? сгибах места , часть текста видна . спасибо ! mariya plekhanova  \n",
            " senior manager of corporate accounts management team \n",
            "\n",
            "\n",
            "\n",
            "\n",
            " tel . :    + 7 ( 495 ) 374 56 18 \n",
            "\n",
            " mob . : + 7 968 562 84 83 \n",
            "\n",
            " г. москва , \n",
            " бц « золото » , ул. золотая , д.11 . awatera.com [ http://awatera.com/ ] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " [ https://img-fotki.yandex.ru/get/6844/65387414.7c0/0_125fa2_7dacd245_xl.gif ] \n",
            " [ https://www.liveinternet.ru/journal_proc.php?action=redirect&url=https://fotki.yandex.ru/users/shadrinagalin/view/1204130/ ] \n",
            " _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            " наша компания рада оказать дополнительные услуги : \n",
            "\n",
            "\n",
            "\n",
            "  * закупка доставка товаров - рубежа ;  \n",
            "  * получение справки мвд ( справка отсутствии судимости ) ;  \n",
            "  * помощь релокации бизнеса : https://relocation.awatera.com/  \n",
            "  * окажем услуги нотариального заверения , апостилирования легализации \n",
            "    документов ( т . ч . консульской ) ;  \n",
            "  * speakus - облачная платформа удаленного синхронного перевода ;  \n",
            "  * локализацию слоганов , брошюр , описание продукта , пользовательский \n",
            "    инструкций ;  \n",
            "  * локализация мультимедийных материалов ;  \n",
            "  * копирайтинг рерайтинг маркетинговых материалов ;  \n",
            "  * транскрипция лингвистическая экспертиза названий ;  \n",
            "  * дизайн многоязычная верстка ;  \n",
            "  * сайты ключ ; идеи реализации ( своя студия веб дизайна ) ;  \n",
            "  * видеопродакшн ( создание роликов нуля , подключение любом этапе ) .\n",
            "GPT response:  \"негатив\", \"плохое качество перевода или вёрстки\"\n",
            "Обработаны файлы и сохранен объединенный файл /content/drive/My Drive/emails for sentiment/combined_file.xlsx\n"
          ]
        }
      ]
    }
  ]
}